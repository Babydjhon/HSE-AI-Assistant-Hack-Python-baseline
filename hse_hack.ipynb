{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install transformers\n",
    "%pip install --upgrade huggingface_hub\n",
    "%pip install flash-attn\n",
    "%pip install --upgrade accelerate\n",
    "%pip install openpyxl\n",
    "%pip install datasets\n",
    "%pip install peft\n",
    "%pip install --upgrade trl\n",
    "%pip install tensorflow\n",
    "%pip install torch\n",
    "%pip install pandas\n",
    "%pip install tf-keras\n",
    "%pip install scikit-learn\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.34.2\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy<3.0.0,>=1.17 (from accelerate==0.34.2)\n",
      "  Using cached numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting packaging>=20.0 (from accelerate==0.34.2)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting psutil (from accelerate==0.34.2)\n",
      "  Using cached psutil-6.1.0-cp37-abi3-win_amd64.whl.metadata (23 kB)\n",
      "Collecting pyyaml (from accelerate==0.34.2)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting torch>=1.10.0 (from accelerate==0.34.2)\n",
      "  Using cached torch-2.5.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate==0.34.2)\n",
      "  Using cached huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate==0.34.2)\n",
      "  Using cached safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests (from huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached setuptools-75.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting colorama (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate==0.34.2)\n",
      "  Using cached MarkupSafe-3.0.1-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Using cached huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Using cached numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Using cached torch-2.5.0-cp312-cp312-win_amd64.whl (203.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached psutil-6.1.0-cp37-abi3-win_amd64.whl (254 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached MarkupSafe-3.0.1-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, sympy, setuptools, safetensors, pyyaml, psutil, packaging, numpy, networkx, MarkupSafe, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, requests, jinja2, torch, huggingface-hub, accelerate\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.5\n",
      "    Uninstalling safetensors-0.4.5:\n",
      "      Successfully uninstalled safetensors-0.4.5\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.1.0\n",
      "    Uninstalling psutil-6.1.0:\n",
      "      Successfully uninstalled psutil-6.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.1\n",
      "    Uninstalling networkx-3.4.1:\n",
      "      Successfully uninstalled networkx-3.4.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.1\n",
      "    Uninstalling MarkupSafe-3.0.1:\n",
      "      Successfully uninstalled MarkupSafe-3.0.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.16.1\n",
      "    Uninstalling filelock-3.16.1:\n",
      "      Successfully uninstalled filelock-3.16.1\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.0\n",
      "    Uninstalling charset-normalizer-3.4.0:\n",
      "      Successfully uninstalled charset-normalizer-3.4.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.5\n",
      "    Uninstalling tqdm-4.66.5:\n",
      "      Successfully uninstalled tqdm-4.66.5\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0\n",
      "    Uninstalling torch-2.5.0:\n",
      "      Successfully uninstalled torch-2.5.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.25.2\n",
      "    Uninstalling huggingface-hub-0.25.2:\n",
      "      Successfully uninstalled huggingface-hub-0.25.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.31.0\n",
      "    Uninstalling accelerate-0.31.0:\n",
      "      Successfully uninstalled accelerate-0.31.0\n",
      "Successfully installed MarkupSafe-3.0.1 accelerate-0.34.2 certifi-2024.8.30 charset-normalizer-3.4.0 colorama-0.4.6 filelock-3.16.1 fsspec-2024.9.0 huggingface-hub-0.25.2 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.1 numpy-2.1.2 packaging-24.1 psutil-6.1.0 pyyaml-6.0.2 requests-2.32.3 safetensors-0.4.5 setuptools-75.2.0 sympy-1.13.1 torch-2.5.0 tqdm-4.66.5 typing-extensions-4.12.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~afetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~sutil'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\numpy\\~ore'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\numpy\\~ft'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\numpy\\~inalg'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\numpy\\~andom'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~harset_normalizer'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.0.1 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2024.9.0 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.1.2 which is incompatible.\n",
      "trl 0.11.4 requires numpy<2; platform_system == \"Windows\", but you have numpy 2.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall accelerate==0.34.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\markg\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]\n",
      "c:\\Users\\markg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve the linear equation 2x + 3 = 7, follow these steps:\n",
      "\n",
      "Step 1: Isolate the variable term (2x) by subtracting 3 from both sides of the equation.\n",
      "2x + 3 - 3 = 7 - 3\n",
      "2x = 4\n",
      "\n",
      "Step 2: Solve for x by dividing both sides of the equation by the coefficient of x, which is 2.\n",
      "2x / 2 = 4 / 2\n",
      "x = 2\n",
      "\n",
      "So, the solution to the equation 2x + 3 = 7 is x = 2.\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3.5-mini-instruct\", \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3ForCausalLM(\n",
       "  (model): Phi3Model(\n",
       "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Phi3DecoderLayer(\n",
       "        (self_attn): Phi3Attention(\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
       "          (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Phi3MLP(\n",
       "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Phi3RMSNorm()\n",
       "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_attention_layernorm): Phi3RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Phi3RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТы - полезный универсальный помощник AI. Всегда готов помочь и всегда решаешь задачу правильно и до конца.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТвоя задача - найти единственный действительный корень уравнения x^3 + 2x^2 + 3x + 4 = 0\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m generation_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4096\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_full_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# \"temperature\": 0.0,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_args)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Ты - полезный универсальный помощник AI. Всегда готов помочь и всегда решаешь задачу правильно и до конца.\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Твоя задача - найти единственный действительный корень уравнения x^3 + 2x^2 + 3x + 4 = 0\"},\n",
    "]\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"return_full_text\": False,\n",
    "    # \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1637, 11)\n",
      "Index(['id', 'task_id', 'student_solution', 'author_comment', 'description',\n",
      "       'author_solution', 'id_test', 'number', 'type', 'input', 'output'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob('hackaton_files/for_teams/train/*.xlsx')\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for file in file_list:\n",
    "    file_name = file.split('\\\\')[-1].split('.')[0]\n",
    "    dataframes[file_name] = pd.read_excel(file)\n",
    "\n",
    "# Переименовываем колонку 'id' в таблице tasks в 'task_id' \n",
    "dataframes['tasks'].rename(columns={'id': 'task_id'}, inplace=True)\n",
    "\n",
    "# Сначала мерджим solutions с tasks\n",
    "solutions_tasks_df = pd.merge(dataframes['solutions'], dataframes['tasks'], on='task_id')\n",
    "\n",
    "# Затем мерджим solutions_tasks  с tests\n",
    "train_df = pd.merge(solutions_tasks_df, dataframes['tests'], on=['task_id'], suffixes=('', '_test'))\n",
    "\n",
    "\n",
    "train_df = train_df.loc[:, ~train_df.columns.duplicated()]\n",
    "train_df.drop(columns=['author_comment_embedding', 'level'], inplace=True)\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>description</th>\n",
       "      <th>author_solution</th>\n",
       "      <th>id_test</th>\n",
       "      <th>number</th>\n",
       "      <th>type</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>open</td>\n",
       "      <td>#a7f0ca</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>#e4e3b3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>open</td>\n",
       "      <td>#a7a8f0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>closed</td>\n",
       "      <td>#c0ced7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>closed</td>\n",
       "      <td>#a7f0ca</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>open</td>\n",
       "      <td>#a7f0ca</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>#e4e3b3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>open</td>\n",
       "      <td>#a7a8f0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>closed</td>\n",
       "      <td>#c0ced7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>Ошибка в открытых тестах. \\n\\nОбратите внимани...</td>\n",
       "      <td>Реализуйте программу, которая проверит, что цв...</td>\n",
       "      <td>logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>closed</td>\n",
       "      <td>#a7f0ca</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  task_id                                   student_solution  \\\n",
       "0  13        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "1  13        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "2  13        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "3  13        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "4  13        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "5  14        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "6  14        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "7  14        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "8  14        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "9  14        1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...   \n",
       "\n",
       "                                      author_comment  \\\n",
       "0  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "1  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "2  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "3  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "4  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "5  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "6  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "7  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "8  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "9  Ошибка в открытых тестах. \\n\\nОбратите внимани...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Реализуйте программу, которая проверит, что цв...   \n",
       "1  Реализуйте программу, которая проверит, что цв...   \n",
       "2  Реализуйте программу, которая проверит, что цв...   \n",
       "3  Реализуйте программу, которая проверит, что цв...   \n",
       "4  Реализуйте программу, которая проверит, что цв...   \n",
       "5  Реализуйте программу, которая проверит, что цв...   \n",
       "6  Реализуйте программу, которая проверит, что цв...   \n",
       "7  Реализуйте программу, которая проверит, что цв...   \n",
       "8  Реализуйте программу, которая проверит, что цв...   \n",
       "9  Реализуйте программу, которая проверит, что цв...   \n",
       "\n",
       "                                     author_solution  id_test  number    type  \\\n",
       "0  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        5       0    open   \n",
       "1  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        6       1    open   \n",
       "2  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        7       2    open   \n",
       "3  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        8       3  closed   \n",
       "4  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        9       4  closed   \n",
       "5  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        5       0    open   \n",
       "6  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        6       1    open   \n",
       "7  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        7       2    open   \n",
       "8  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        8       3  closed   \n",
       "9  logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4...        9       4  closed   \n",
       "\n",
       "     input output  \n",
       "0  #a7f0ca   True  \n",
       "1  #e4e3b3  False  \n",
       "2  #a7a8f0  False  \n",
       "3  #c0ced7  False  \n",
       "4  #a7f0ca   True  \n",
       "5  #a7f0ca   True  \n",
       "6  #e4e3b3  False  \n",
       "7  #a7a8f0  False  \n",
       "8  #c0ced7  False  \n",
       "9  #a7f0ca   True  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1637 entries, 0 to 1636\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   id                        1637 non-null   int64 \n",
      " 1   task_id                   1637 non-null   int64 \n",
      " 2   student_solution          1637 non-null   object\n",
      " 3   author_comment            1637 non-null   object\n",
      " 4   author_comment_embedding  1637 non-null   object\n",
      " 5   level                     1637 non-null   object\n",
      " 6   description               1637 non-null   object\n",
      " 7   author_solution           1637 non-null   object\n",
      " 8   id_test                   1637 non-null   int64 \n",
      " 9   number                    1637 non-null   int64 \n",
      " 10  type                      1637 non-null   object\n",
      " 11  input                     1454 non-null   object\n",
      " 12  output                    1482 non-null   object\n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 166.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year = input()\n",
      "\n",
      "with open('projects_file.csv', 'r', encoding='utf-8') as my_file:\n",
      "    for line in my_file:\n",
      "        line = line.strip()\n",
      "        info = line.split(',')\n",
      "        if info[0] <= year and int(info[2].split()[0]) <= 500:\n",
      "            print(line)\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "print(train_df['student_solution'].iloc[randint(0, train_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1778, 11)\n",
      "Index(['id', 'task_id', 'student_solution', 'author_comment', 'description',\n",
      "       'author_solution', 'id_test', 'number', 'type', 'input', 'output'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob('hackaton_files/for_teams/test/*.xlsx')\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for file in file_list:\n",
    "    file_name = file.split('\\\\')[-1].split('.')[0]\n",
    "    dataframes[file_name] = pd.read_excel(file)\n",
    "\n",
    "# Переименовываем 'id' в 'task_id' в таблице tasks\n",
    "dataframes['tasks'].rename(columns={'id': 'task_id'}, inplace=True)\n",
    "\n",
    "# Мерджим solutions с tasks\n",
    "solutions_tasks_df = pd.merge(dataframes['solutions'], dataframes['tasks'], on='task_id')\n",
    "\n",
    "# Мерджим результат с tests\n",
    "test_df = pd.merge(solutions_tasks_df, dataframes['tests'], on=['task_id'], suffixes=('', '_test'))\n",
    "\n",
    "test_df = test_df.loc[:, ~test_df.columns.duplicated()]\n",
    "test_df.drop(columns=['author_comment_embedding', 'level'], inplace=True)\n",
    "\n",
    "test_df.to_csv('test_data.csv', index=False) # Исправлено название файла\n",
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>student_solution</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>description</th>\n",
       "      <th>author_solution</th>\n",
       "      <th>id_test</th>\n",
       "      <th>number</th>\n",
       "      <th>type</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>open</td>\n",
       "      <td>0.1; 500</td>\n",
       "      <td>Реализация проекта будет стоить 500 тыс. руб. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>0.05; 900000</td>\n",
       "      <td>Реализация проекта будет стоить 900000 тыс. ру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>open</td>\n",
       "      <td>0; 2345678</td>\n",
       "      <td>Реализация проекта будет стоить 2345678 тыс. р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>closed</td>\n",
       "      <td>0.5; 100</td>\n",
       "      <td>Реализация проекта будет стоить 100 тыс. руб. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>closed</td>\n",
       "      <td>0.003; 12345667</td>\n",
       "      <td>Реализация проекта будет стоить 12345667 тыс. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>open</td>\n",
       "      <td>0.1; 500</td>\n",
       "      <td>Реализация проекта будет стоить 500 тыс. руб. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>open</td>\n",
       "      <td>0.05; 900000</td>\n",
       "      <td>Реализация проекта будет стоить 900000 тыс. ру...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>open</td>\n",
       "      <td>0; 2345678</td>\n",
       "      <td>Реализация проекта будет стоить 2345678 тыс. р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>closed</td>\n",
       "      <td>0.5; 100</td>\n",
       "      <td>Реализация проекта будет стоить 100 тыс. руб. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>Ваше предсказание</td>\n",
       "      <td>Реализуйте программу, которая напечатает стоим...</td>\n",
       "      <td>discount  = float(input())\\nmoney = int(input(...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>closed</td>\n",
       "      <td>0.003; 12345667</td>\n",
       "      <td>Реализация проекта будет стоить 12345667 тыс. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  task_id                                   student_solution  \\\n",
       "0   0        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "1   0        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "2   0        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "3   0        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "4   0        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "5   1        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "6   1        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "7   1        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "8   1        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "9   1        0  discount  = float(input())\\nmoney = int(input(...   \n",
       "\n",
       "      author_comment                                        description  \\\n",
       "0  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "1  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "2  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "3  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "4  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "5  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "6  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "7  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "8  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "9  Ваше предсказание  Реализуйте программу, которая напечатает стоим...   \n",
       "\n",
       "                                     author_solution  id_test  number    type  \\\n",
       "0  discount  = float(input())\\nmoney = int(input(...        0       0    open   \n",
       "1  discount  = float(input())\\nmoney = int(input(...        1       1    open   \n",
       "2  discount  = float(input())\\nmoney = int(input(...        2       2    open   \n",
       "3  discount  = float(input())\\nmoney = int(input(...        3       3  closed   \n",
       "4  discount  = float(input())\\nmoney = int(input(...        4       4  closed   \n",
       "5  discount  = float(input())\\nmoney = int(input(...        0       0    open   \n",
       "6  discount  = float(input())\\nmoney = int(input(...        1       1    open   \n",
       "7  discount  = float(input())\\nmoney = int(input(...        2       2    open   \n",
       "8  discount  = float(input())\\nmoney = int(input(...        3       3  closed   \n",
       "9  discount  = float(input())\\nmoney = int(input(...        4       4  closed   \n",
       "\n",
       "             input                                             output  \n",
       "0         0.1; 500  Реализация проекта будет стоить 500 тыс. руб. ...  \n",
       "1     0.05; 900000  Реализация проекта будет стоить 900000 тыс. ру...  \n",
       "2       0; 2345678  Реализация проекта будет стоить 2345678 тыс. р...  \n",
       "3         0.5; 100  Реализация проекта будет стоить 100 тыс. руб. ...  \n",
       "4  0.003; 12345667  Реализация проекта будет стоить 12345667 тыс. ...  \n",
       "5         0.1; 500  Реализация проекта будет стоить 500 тыс. руб. ...  \n",
       "6     0.05; 900000  Реализация проекта будет стоить 900000 тыс. ру...  \n",
       "7       0; 2345678  Реализация проекта будет стоить 2345678 тыс. р...  \n",
       "8         0.5; 100  Реализация проекта будет стоить 100 тыс. руб. ...  \n",
       "9  0.003; 12345667  Реализация проекта будет стоить 12345667 тыс. ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1778 entries, 0 to 1777\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                1778 non-null   int64 \n",
      " 1   task_id           1778 non-null   int64 \n",
      " 2   student_solution  1778 non-null   object\n",
      " 3   author_comment    1778 non-null   object\n",
      " 4   description       1778 non-null   object\n",
      " 5   author_solution   1778 non-null   object\n",
      " 6   id_test           1778 non-null   int64 \n",
      " 7   number            1778 non-null   int64 \n",
      " 8   type              1778 non-null   object\n",
      " 9   input             1778 non-null   object\n",
      " 10  output            1623 non-null   object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 152.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['author_comment']\n",
    "X_train = train_df.drop(columns=['author_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'task_id', 'student_solution', 'description', 'author_solution',\n",
       "       'id_test', 'number', 'type', 'input', 'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts(X_train):\n",
    "    prompts = []\n",
    "    for index, row in X_train.iterrows():\n",
    "        student_solution = row['student_solution']\n",
    "        description = row['description']\n",
    "        author_solution = row['author_solution']\n",
    "        test_input = row['input'] if pd.notna(row['input']) else \"\"\n",
    "        test_output = row['output'] if pd.notna(row['output']) else \"\"\n",
    "        prompt = f\"\"\"\n",
    "Представь, что ты гениальный преподаватель по программированию. Ты проверяешь работы своих студентов.\n",
    "Тебе даны следующие данные:\n",
    "Условие задания:\n",
    "```\n",
    "{description}\n",
    "```\n",
    "\n",
    "Авторское решение:\n",
    "```python\n",
    "{author_solution}\n",
    "```\n",
    "\n",
    "Решение студента:\n",
    "```python\n",
    "{student_solution}\n",
    "```\n",
    "\n",
    "Входные данные теста:\n",
    "```\n",
    "{test_input}\n",
    "```\n",
    "\n",
    "Выходные данные теста:\n",
    "```\n",
    "{test_output}\n",
    "```\n",
    "\n",
    "Твоя задача - найти у студента ошибку и написать безупречный комментарий к решению студента, кратко описав его ошибку. Нельзя давать студенту готовое решение, но можно подсказать, в каком направлении двигаться. Также нельзя давать студенту тесты. Также нельзя давать студенту неверную информацию.\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Представь, что ты гениальный преподаватель по программированию. Ты проверяешь работы своих студентов.\n",
      "Тебе даны следующие данные:\n",
      "Условие задания:\n",
      "```\n",
      "Реализуйте программу, которая проверит, что цвет используется только в проекте по созданию логотипа, но не в проекте по созданию дизайна сайта:\n",
      "\n",
      "Даны два списка logo_project и cite_project с кодами используемых цветов (строки).\n",
      "В переменную color считывается код цвета (строка). Этот код уже написан.\n",
      "Программа должна проверять, что код цвета color есть только в списке logo_project, и если да, то печатать True. \n",
      "В остальных случаях программа печатает False. \n",
      "```\n",
      "\n",
      "Авторское решение:\n",
      "```python\n",
      "logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4', '#e4b3cd', '#e4e3b3', '#c0ced7']\n",
      "cite_project = ['#e4e3b3', '#a7a8f0', '#ccb1e6', '#b4f99e', '#f9b59e', '#c0ced7']\n",
      "\n",
      "color = input()\n",
      "\n",
      "if color in logo_project and not(color in cite_project):\n",
      "    print(True)\n",
      "else:\n",
      "    print(False)\n",
      "```\n",
      "\n",
      "Решение студента:\n",
      "```python\n",
      "logo_project = ['#a7a8f0', '#a7f0ca', '#b3b4e4', '#e4b3cd', '#e4e3b3', '#c0ced7']\n",
      "cite_project = ['#e4e3b3', '#a7a8f0', '#ccb1e6', '#b4f99e', '#f9b59e', '#c0ced7']\n",
      "\n",
      "color = input()\n",
      "\n",
      "if color in logo_project and color in cite_project:\n",
      "    print(True)\n",
      "else:\n",
      "    print(False)\n",
      "```\n",
      "\n",
      "Входные данные теста:\n",
      "```\n",
      "#a7f0ca\n",
      "```\n",
      "\n",
      "Выходные данные теста:\n",
      "```\n",
      "True\n",
      "```\n",
      "\n",
      "Твоя задача - найти у студента ошибку и написать безупречный комментарий к решению студента, кратко описав его ошибку. Нельзя давать студенту готовое решение, но можно подсказать, в каком направлении двигаться. Также нельзя давать студенту тесты. Также нельзя давать студенту неверную информацию.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(create_prompts(X_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-10-18 02:56:20 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: False\n",
      "2024-10-18 02:56:20 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./checkpoint_dir\\runs\\Oct18_02-56-20_Marqich-LAPTOP,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./checkpoint_dir,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./checkpoint_dir,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2024-10-18 02:56:20 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules='all-linear', lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:675] 2024-10-18 02:56:20,920 >> loading configuration file config.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\config.json\n",
      "[INFO|configuration_utils.py:675] 2024-10-18 02:56:21,085 >> loading configuration file config.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\config.json\n",
      "[INFO|configuration_utils.py:742] 2024-10-18 02:56:21,087 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"microsoft/Phi-3.5-mini-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"long_factor\": [\n",
      "      1.0800000429153442,\n",
      "      1.1100000143051147,\n",
      "      1.1399999856948853,\n",
      "      1.340000033378601,\n",
      "      1.5899999141693115,\n",
      "      1.600000023841858,\n",
      "      1.6200000047683716,\n",
      "      2.620000123977661,\n",
      "      3.2300000190734863,\n",
      "      3.2300000190734863,\n",
      "      4.789999961853027,\n",
      "      7.400000095367432,\n",
      "      7.700000286102295,\n",
      "      9.09000015258789,\n",
      "      12.199999809265137,\n",
      "      17.670000076293945,\n",
      "      24.46000099182129,\n",
      "      28.57000160217285,\n",
      "      30.420001983642578,\n",
      "      30.840002059936523,\n",
      "      32.590003967285156,\n",
      "      32.93000411987305,\n",
      "      42.320003509521484,\n",
      "      44.96000289916992,\n",
      "      50.340003967285156,\n",
      "      50.45000457763672,\n",
      "      57.55000305175781,\n",
      "      57.93000411987305,\n",
      "      58.21000289916992,\n",
      "      60.1400032043457,\n",
      "      62.61000442504883,\n",
      "      62.62000274658203,\n",
      "      62.71000289916992,\n",
      "      63.1400032043457,\n",
      "      63.1400032043457,\n",
      "      63.77000427246094,\n",
      "      63.93000411987305,\n",
      "      63.96000289916992,\n",
      "      63.970001220703125,\n",
      "      64.02999877929688,\n",
      "      64.06999969482422,\n",
      "      64.08000183105469,\n",
      "      64.12000274658203,\n",
      "      64.41000366210938,\n",
      "      64.4800033569336,\n",
      "      64.51000213623047,\n",
      "      64.52999877929688,\n",
      "      64.83999633789062\n",
      "    ],\n",
      "    \"short_factor\": [\n",
      "      1.0,\n",
      "      1.0199999809265137,\n",
      "      1.0299999713897705,\n",
      "      1.0299999713897705,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0699999332427979,\n",
      "      1.0999999046325684,\n",
      "      1.1099998950958252,\n",
      "      1.1599998474121094,\n",
      "      1.1599998474121094,\n",
      "      1.1699998378753662,\n",
      "      1.2899998426437378,\n",
      "      1.339999794960022,\n",
      "      1.679999828338623,\n",
      "      1.7899998426437378,\n",
      "      1.8199998140335083,\n",
      "      1.8499997854232788,\n",
      "      1.8799997568130493,\n",
      "      1.9099997282028198,\n",
      "      1.9399996995925903,\n",
      "      1.9899996519088745,\n",
      "      2.0199997425079346,\n",
      "      2.0199997425079346,\n",
      "      2.0199997425079346,\n",
      "      2.0199997425079346,\n",
      "      2.0199997425079346,\n",
      "      2.0199997425079346,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0299997329711914,\n",
      "      2.0799996852874756,\n",
      "      2.0899996757507324,\n",
      "      2.189999580383301,\n",
      "      2.2199995517730713,\n",
      "      2.5899994373321533,\n",
      "      2.729999542236328,\n",
      "      2.749999523162842,\n",
      "      2.8399994373321533\n",
      "    ],\n",
      "    \"type\": \"longrope\"\n",
      "  },\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 262144,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:21 - WARNING - transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3 - `flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "2024-10-18 02:56:21 - WARNING - transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3 - Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3732] 2024-10-18 02:56:21,369 >> loading weights file model.safetensors from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\model.safetensors.index.json\n",
      "[INFO|configuration_utils.py:1099] 2024-10-18 02:56:21,373 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.94s/it]\n",
      "[INFO|modeling_utils.py:4574] 2024-10-18 02:56:47,284 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4582] 2024-10-18 02:56:47,285 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3.5-mini-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1054] 2024-10-18 02:56:47,480 >> loading configuration file generation_config.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\generation_config.json\n",
      "[INFO|configuration_utils.py:1099] 2024-10-18 02:56:47,481 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": [\n",
      "    32007,\n",
      "    32001,\n",
      "    32000\n",
      "  ],\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:47,670 >> loading file tokenizer.model from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:47,671 >> loading file tokenizer.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:47,671 >> loading file added_tokens.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:47,672 >> loading file special_tokens_map.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:47,672 >> loading file tokenizer_config.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2470] 2024-10-18 02:56:47,756 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[INFO|training_args.py:2120] 2024-10-18 02:56:48,343 >> PyTorch: setting up devices\n",
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:195: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:48,500 >> loading file tokenizer.model from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:48,500 >> loading file tokenizer.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:48,501 >> loading file added_tokens.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:48,501 >> loading file special_tokens_map.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2206] 2024-10-18 02:56:48,501 >> loading file tokenizer_config.json from cache at C:\\Users\\markg\\.cache\\huggingface\\hub\\models--microsoft--Phi-3.5-mini-instruct\\snapshots\\af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2470] 2024-10-18 02:56:48,553 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Using custom data configuration default-646415d2491a7716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Using custom data configuration default-646415d2491a7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset Infos from c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\markg\\.cache\\huggingface\\datasets/generator/default-646415d2491a7716/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset info from C:\\Users\\markg\\.cache\\huggingface\\datasets/generator/default-646415d2491a7716/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (C:/Users/markg/.cache/huggingface/datasets/generator/default-646415d2491a7716/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Found cached dataset generator (C:/Users/markg/.cache/huggingface/datasets/generator/default-646415d2491a7716/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/markg/.cache/huggingface/datasets/generator/default-646415d2491a7716/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset info from C:/Users/markg/.cache/huggingface/datasets/generator/default-646415d2491a7716/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ff9c330467bb1170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Using custom data configuration default-ff9c330467bb1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset Infos from c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\markg\\.cache\\huggingface\\datasets/generator/default-ff9c330467bb1170/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset info from C:\\Users\\markg\\.cache\\huggingface\\datasets/generator/default-ff9c330467bb1170/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (C:/Users/markg/.cache/huggingface/datasets/generator/default-ff9c330467bb1170/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.builder - Found cached dataset generator (C:/Users/markg/.cache/huggingface/datasets/generator/default-ff9c330467bb1170/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/markg/.cache/huggingface/datasets/generator/default-ff9c330467bb1170/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:48 - INFO - datasets.info - Loading Dataset info from C:/Users/markg/.cache/huggingface/datasets/generator/default-ff9c330467bb1170/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:667] 2024-10-18 02:56:49,065 >> Using cpu_amp half precision backend\n",
      "[INFO|trainer.py:2243] 2024-10-18 02:56:50,336 >> ***** Running training *****\n",
      "[INFO|trainer.py:2244] 2024-10-18 02:56:50,337 >>   Num examples = 566\n",
      "[INFO|trainer.py:2245] 2024-10-18 02:56:50,337 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2246] 2024-10-18 02:56:50,337 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2249] 2024-10-18 02:56:50,338 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2250] 2024-10-18 02:56:50,338 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2251] 2024-10-18 02:56:50,338 >>   Total optimization steps = 142\n",
      "[INFO|trainer.py:2252] 2024-10-18 02:56:50,339 >>   Number of trainable parameters = 3,821,079,552\n",
      "  0%|          | 0/142 [00:00<?, ?it/s]c:\\prog\\Hackaton HSE Python AI\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3451: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-18 02:56:51 - WARNING - transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3 - You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "\n",
    "from dataclasses import asdict\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    \"report_to\": \"none\"\n",
    "    }\n",
    "\n",
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)\n",
    "\n",
    "\n",
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")\n",
    "\n",
    "\n",
    "################\n",
    "# Model Loading\n",
    "################\n",
    "\n",
    "checkpoint_path = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\",  # loading the model with flash-attenstion support\n",
    "    # device_map=\"auto\"\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "##################\n",
    "# Разделение данных на тренировочный и валидационный наборы\n",
    "##################\n",
    "X_train_split, X_eval_split, y_train_split, y_eval_split = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "##################\n",
    "# Подготовка промптов\n",
    "##################\n",
    "prompts_train = create_prompts(X_train_split)\n",
    "prompts_eval = create_prompts(X_eval_split)\n",
    "##################\n",
    "# Токенизация labels\n",
    "##################\n",
    "y_train_tokenized = tokenizer(y_train_split.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "y_eval_tokenized = tokenizer(y_eval_split.tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "##################\n",
    "# Создание датасета для TRL\n",
    "##################\n",
    "train_dataset = Dataset.from_dict({\"text\": prompts_train, \"labels\": y_train_tokenized[\"input_ids\"].tolist()})\n",
    "eval_dataset = Dataset.from_dict({\"text\": prompts_eval, \"labels\": y_eval_tokenized[\"input_ids\"].tolist()})\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Токенизируем и промпты, и метки (ответы) внутри preprocess_function\n",
    "    inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=2048, return_tensors=\"pt\")\n",
    "    labels = tokenizer(examples[\"labels\"], padding=\"max_length\", truncation=True, max_length=2048, return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"]\n",
    "    }\n",
    "    return model_inputs\n",
    "\n",
    "###########\n",
    "# Training\n",
    "###########\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    max_seq_length=2048,  #  Установи в соответствии с длиной твоих промптов\n",
    "    dataset_text_field=\"text\",  #  Ключ для текста промпта в датасете\n",
    "    packing=preprocess_function,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "\n",
    "# def custom_to_json_string(self):\n",
    "#     config_dict = asdict(self)\n",
    "#     # Фильтруем несериализуемые объекты\n",
    "#    serializable_config = {k: v for k, v in config_dict.items() if not callable(v)}\n",
    "#     return json.dumps(serializable_config, indent=2)\n",
    "# TrainingArguments.to_json_string = custom_to_json_string\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "\n",
    "#############\n",
    "# Evaluation\n",
    "#############\n",
    "tokenizer.padding_side = 'left'\n",
    "metrics = trainer.evaluate()\n",
    "metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "\n",
    "# ############\n",
    "# # Save model\n",
    "# ############\n",
    "trainer.save_model(train_conf.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)  #  Тот же checkpoint, что и при тренировке\n",
    "\n",
    "# Загрузка модели с учетом LoRA весов\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./checkpoint_dir\", peft_config=peft_config)\n",
    "\n",
    "# Создание pipeline для генерации текста\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "prompt = \"Напиши комментарий к решению студента: ...\"  # Твой промпт\n",
    "generated_text = pipe(prompt)[0]['generated_text']\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
