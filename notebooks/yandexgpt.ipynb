{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T19:46:23.251578Z",
     "start_time": "2024-10-12T19:46:22.983730Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from app.models.yandexgpt import YandexGPT\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "yandex_gpt = YandexGPT(\n",
    "    token=os.environ[\"YANDEX_GPT_IAM_TOKEN\"],\n",
    "    folder_id=os.environ[\"YANDEX_GPT_FOLDER_ID\"],\n",
    "    system_prompt=\"Ты - профессиональный программист и ментор. Давай очень короткие ответы о синтаксических ошибках в коде, если они есть.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:50:31.583388Z",
     "start_time": "2024-10-12T19:50:30.314617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from app.utils.submit import generate_submit\n",
    "\n",
    "\n",
    "def predict(row: pd.Series) -> str:\n",
    "    return yandex_gpt.ask(row[\"student_solution\"])\n",
    "\n",
    "\n",
    "generate_submit(\n",
    "    test_solutions_path=\"../data/raw/test/solutions.xlsx\",\n",
    "    predict_func=predict,\n",
    "    save_path=\"../data/processed/submission.csv\",\n",
    "    use_tqdm=True,\n",
    ")"
   ],
   "id": "e4365a5b58ee1393",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 1/347 [00:01<07:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 {\"error\":{\"grpcCode\":8,\"httpCode\":429,\"message\":\"ai.textGenerationCompletionSessionsCount.count gauge quota limit exceed: allowed 1 requests\",\"httpStatus\":\"Too Many Requests\",\"details\":[]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(row: pd\u001B[38;5;241m.\u001B[39mSeries) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m yandex_gpt\u001B[38;5;241m.\u001B[39mask(row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstudent_solution\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m----> 8\u001B[0m \u001B[43mgenerate_submit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_solutions_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/raw/test/solutions.xlsx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpredict_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/processed/submission.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/hse-aiahp-baseline/app/utils/submit.py:44\u001B[0m, in \u001B[0;36mgenerate_submit\u001B[0;34m(test_solutions_path, predict_func, save_path, use_tqdm)\u001B[0m\n\u001B[1;32m     40\u001B[0m     solution_row \u001B[38;5;241m=\u001B[39m test_solutions\u001B[38;5;241m.\u001B[39miloc[i]\n\u001B[1;32m     42\u001B[0m     text \u001B[38;5;241m=\u001B[39m predict_func(solution_row)  \u001B[38;5;66;03m# here you can do absolute whatever you want\u001B[39;00m\n\u001B[0;32m---> 44\u001B[0m     embedding \u001B[38;5;241m=\u001B[39m embedding2string(\u001B[43mget_sentence_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     45\u001B[0m     submit_df\u001B[38;5;241m.\u001B[39mloc[i] \u001B[38;5;241m=\u001B[39m [idx, text, embedding]\n\u001B[1;32m     46\u001B[0m submit_df\u001B[38;5;241m.\u001B[39mto_csv(save_path, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/hse-aiahp-baseline/app/utils/submit.py:14\u001B[0m, in \u001B[0;36mget_sentence_embedding\u001B[0;34m(sentence)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_sentence_embedding\u001B[39m(sentence: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m---> 14\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m     16\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n",
      "File \u001B[0;32m~/PycharmProjects/hse-aiahp-baseline/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3010\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   3008\u001B[0m all_kwargs\u001B[38;5;241m.\u001B[39mupdate(kwargs)\n\u001B[1;32m   3009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3010\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to specify either `text` or `text_target`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3012\u001B[0m     \u001B[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001B[39;00m\n\u001B[1;32m   3013\u001B[0m     \u001B[38;5;66;03m# input mode in this case.\u001B[39;00m\n\u001B[1;32m   3014\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n",
      "\u001B[0;31mValueError\u001B[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0526506ea36bc50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
